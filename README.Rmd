---
title: "README"
author: "Kiernan Nicholls"
date: "January 23, 2019"
output: md_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

# _predictr_

Using R to compare the predictive capabilities of markets and models.

1. [Project Background](#project-background)
1. [Predictive Methods](#predictive-methods)
    1. [Polling and Aggregation](###polling-and-aggregation)
    1. [Forecasting Models](#forecasting-models)
    1. [Prediction Markets](#prediction-markets)
1. [Prediction Data](#prediction-data)
    1. [FiveThirtyEight Model](#fivethirtyeight-model)
    1. [PredictIt Markets](#predictit-markets)
1. [Data Wrangling](#data-wrangling)
1. [Data Exploration](#data-exploration)
1. [Project Findings](#project-findings)
1. [Conclusion](#conclusion)
1. [Bibliography](#bibliography)


## Project Background

The forecast model has become a staple of political punditry. Popularized by the
data journalism site [FiveThirtyEight][01], the forecast model is a statistical
tool used to incorporate a number of quantitative inputs and output a
probabilistic view of all possible outcomes.

On the eve of the 2016 Presidential election, all mainstream forecasts gave
Hillary Clinton significant odds to win the presidency. FiveThirtyEight's
forecast model gave Clinton the lowest odds [at 71%][02]. Meanwhile, The New
York Times Upshot calculated [85%][03] and the HuffPo Pollster's published an
infamous [98% chance of a Clinton victory][04].

Is there a better alternative to forecasting models?

Markets can be used to ascertain a probabilistic prediction of election results.
Instead of a incorporating quantitative inputs, a market has self-interested
traders bet on the outcomes to determine the likelihood of each.

This project compares the accuracy of markets and models in their ability to
predict the winner of 2018 midterm congressional elections.

## Predictive Methods

### Polling and Aggrigation

Opinion polling is the most common form of election predicting. 
By [randomly sampling][05] the overall population of potential voters, pollsters
can ask a thousand Americans their voting intentions and determine the likely
division of votes in the actual election. Sampling errors and systemic errors
prevent this statistical tool from perfectly predicting the election. By
aggregating a bunch of polls and averaging their results, sites like
[RealClearPolitics][06] take advantage of the [law of large numbers][07] to
better calculate the true opinion of the population.

### Forecasting Models

In [the word's][08] of Nate Silver, FiveThirtyEight's founder and primary author of
their model:

> (Forecasting models) take lots of polls, perform various types of adjustments
to them, and then blend them with other kinds of empirically useful indicators
(what we sometimes call “the fundamentals”) to forecast each race. Then they
account for the uncertainty in the forecast and simulate the election thousands
of times.

I will be using the FiveThirtyEight model to collect forecasting data. In 2016,
FiveThirtyEight's prediction was closest to reality. They are one of the few
mainstream forecasters to continue their work into the 2018 midterm elections.

The exact process of the FiveThirtyEight is proprietary, so we can't know
exactly what data is being incorporated in what ways. In the "classic" version
of their model, three types of quantitative data are used:

1. **Polling**: District-by-district polling, adjusted for house effects and
other factors in some unknown way. [FiveThirtyEight rates pollsters][09] to
adjust their findings.
2. **C.A.N.T.O.R.**: A proprietary system which infers results for districts
with little or no polling from similar districts where polling has been done.
3. **Fundamentals**: Non-polling factors that historically help in predicting
congressional races:
    * Incumbency
    * State partisanship
    * Incumbent previous margins
    * Generic ballot
    * Fundraising
    * Incumbent voting record
    * Challenger experience
    * Scandals
    
From everything that has been said publicly about the mathematics of their
model, FiveThirtyEight uses these quantitative inputs to predict each
candidate's share of the vote. The model is then uses the statistical program
Stata to run a [Monte Carlo simulation][10]. By predicting the lower limit,
upper limit, central tendency, and distribution of shares of the vote for two
candidates, you can simulate a given election 20,000 times and simply use the
percentage of victories as the probability of actual victory.

In the training data (most House races since 1998), the classic model correctly
predicted _96.7%_ of races at the time of election. FiveThirtyEight points out
that the _vast_ majority of races are blowouts, inflating this accuracy
percentage.

### Prediction Markets

As summarized [on Wikipedia][18]:

> Prediction markets (also known as predictive markets, information markets,
decision markets, idea futures, event derivatives, or virtual markets) are
exchange-traded markets created for the purpose of trading the outcome of
events. The market prices can indicate what the crowd thinks the probability of
the event is. A prediction market contract trades between 0 and 100%... The main
purposes of prediction markets are eliciting aggregating beliefs over an unknown
future outcome. Traders with different beliefs trade on contracts whose payoffs
are related to the unknown future outcome and the market prices of the contracts
are considered as the aggregated belief.

## Prediction Data

### FiveThirtyEight Model

The team at FiveThirtyEight made public a portion of their model's output as
four separate `.csv` files on their website:

1. [Senate national forecast][11]
2. [Senate seat forecast][12]
3. [House national forecast][13]
4. [House district forecasts][14]

The two national forecasts provide the FiveThirtyEight calculations for each
party's probability of winning a majority in their respective chambers on any
given day (e.g., "The Democratic party has an 85% chance of winning a majority
in the House").

The seat and district level forecasts will be used in this project. Each
observation represents one day's probability of victory for one candidate. There
are 28,353 observations in the Senate seat level file and 302,859 for the House
district level. For each observation, there are 12 variables recorded:

1. The date of the prediction (starting on 2018-08-01)
2. The State the election is in
3. The Congressional district the election is in
4. Whether the election is a "special election"
5. The candidate's full name
6. The candidate's political party
7. The model version (classic, lite, or deluxe)
8. The candidate's probability of victory
9. The candidate's expected share of the vote (50th percentile)
10. The candidate's ~minimum share of the vote (10th percentile)
10. The candidate's ~maximum share of the vote (90th percentile)

Below is a sample of variables to show the structure of the data as provided by
FiveThirtyEight.

```{r model_data, echo=FALSE, message=FALSE}
read_csv("./input/model_district.csv") %>% 
  select(-candidate,
         -special, 
         -model,
         -p10_voteshare, 
         -p90_voteshare) %>% 
  print()
```

### PredictIt Markets

PredictIt markets are comprised of "markets" and "contracts." As they explain on
[their website][15]:

> Every question posed by PredictIt is known as a ‘market’. Some markets have
simple yes or no answers, while others can have multiple possible answers.

> Each possible answer to the question posed in a market is known as a
‘contract’. Markets that ask simple yes or no answers are known as
‘single-contract markets’, while those with multiple possible choices – like the
winner of an election – are called ‘multiple-contract markets’...
Single-contract markets resolve either to ‘Yes’ or ‘No’. In multiple-contract
markets, only one contract can resolve to ‘Yes’. All others will resolve to
‘No’.

On [their webstie][16], PredictIt outlines their data agreement with academic
researchers:

> In order to take full advantage of the research opportunities presented by
prediction markets like PredictIt, we make our data available to members of the
academic community at no cost. PredictIt’s market data offers researchers a
wealth of information that can be used to further our understanding of a wide
array of subjects in fields of study as diverse as microeconomics, political
behavior, computer science and game theory.

I scraped [the PredictIt API][17] before the election and used the data to find
all market ID's related to Congressional elections. PredictIt then provided the
relevant market data as a `.csv` file.

Each observation represents one day's opening, closing, low, and high price for
a single contract from a single market. There are 44,711 observations covering
145 contracts across 118 markets. For each observation there are 11 variables:

1. Market ID
2. Market name (the "question" being asked)
3. Market symbol
4. Contract name (the possible "answers")
5. Contract symbol
6. Prediction date (earliest is 201-01-27)
7. Opening contract price
8. Low contract price
9. High contract price
10. Closing contract price (that day's final prediction)

Below is a random sample of observations with a selection of variables to show
the structure of the data as provided by PredictIt:

```{r market_data, echo=FALSE, message=FALSE}
read_csv(file = "./input/market_data.csv",
         na = c("n/a", "NA"),
         col_types = cols(MarketId = col_character(),
                          ContractName = col_character(),
                          ContractSymbol = col_character())) %>%
  # Randomly arrange the tibble
  mutate(rand = sample(1:nrow(.), nrow(.), replace = F)) %>%
  arrange(rand) %>% 
  select(-MarketName, 
         -ContractName, 
         -LowPrice, 
         -OpenPrice, 
         -HighPrice,
         -rand) %>% 
  print()
```

## Data Wrangling

By formatting the above data sets to contain relational keys of `date`, `code`,
and `party` we can perform a left-wise join on the data to combine the prediction
data from the PredictIt markets and FiveThirtyEight model. The `code` variable
is the primary key, created with the `state` and `district` variables from
FiveThirtyEight and the `ContractSymbol` variable from PredictIt. For House
races, the number is the Congressional District. For Senate races, "-99"
indicates a on-time election and "-98" indicates a special election.

We then gather the variables to make out data frame "tidy" with each observation
representing one prediction (on one date, for one candidate, with one method).
The resulting data set has 29,602 observations with nine variables.

```{r joined_probs, echo=FALSE, message=FALSE}
read_csv("./output/joined_probs.csv") %>% 
  print()
```

## Data Exploration

## Project Findings

## Conclusion

## Biblography

[01]: https://fivethirtyeight.com/ "538 home page"
[02]: https://goo.gl/CLPrUC "538 2016"
[03]: https://goo.gl/QES9vJ "NYT Upshot 2016"
[04]: https://goo.gl/XJqwyD "HuffPo 2016"
[05]: https://en.wikipedia.org/wiki/Sampling_(statistics) "Sandom sampling wiki"
[06]: https://www.realclearpolitics.com/ "RCP home page"
[07]: https://en.wikipedia.org/wiki/Law_of_large_numbers "Law large nums wiki"
[08]: https://fivethirtyeight.com/methodology/how-fivethirtyeights-house-and-senate-models-work/ "538 model how"
[09]: https://projects.fivethirtyeight.com/pollster-ratings/ "538 poll ratings"
[10]: https://en.wikipedia.org/wiki/Monte_Carlo_method "Monte carlo sim wiki"
[11]: https://projects.fivethirtyeight.com/congress-model-2018/senate_national_forecast.csv "Sen nat model"
[12]: https://projects.fivethirtyeight.com/congress-model-2018/senate_seat_forecast.csv "Sen seat model"
[13]: https://projects.fivethirtyeight.com/congress-model-2018/house_national_forecast.csv "House nat model"
[14]: https://projects.fivethirtyeight.com/congress-model-2018/house_district_forecast.csv "House dis model"
[15]: https://www.predictit.org/support/faq "PredictIt FAQ"
[16]: https://www.predictit.org/research "PredictIt research"
[17]: https://www.predictit.org/api/marketdata/all/ "PredictIt API"
[18]: https://en.wikipedia.org/wiki/Prediction_market "Prediction markets wiki"
